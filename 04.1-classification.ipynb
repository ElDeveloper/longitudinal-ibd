{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import qiime2 as q2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from skbio import TreeNode\n",
    "from biom import load_table, Table\n",
    "\n",
    "from featlib import Sculptor, load_mf\n",
    "from featlib.extractor import abs_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot aesthetics homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load three files, the OTU table, a phylogenetic tree corresponding to that table and a metadata mapping file. The metadata file must include a gradient column, in our case ``days_since_epoch`` (we convert this into a numeric column).\n",
    "\n",
    "\n",
    "The table is rarefied at 4,000 sequences per sample, this could be changed but at this level we can keep a large number of subjects and samples per subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rarefy before renaming\n",
    "bt = load_table('otu-table.noblanks.biom')\n",
    "bt = bt.subsample(4000)\n",
    "\n",
    "mf = load_mf('mapping-file.alpha.txt')\n",
    "\n",
    "# we only keep the samples that have sequences in the table\n",
    "mf = mf.loc[bt.ids()].copy()\n",
    "\n",
    "tree = TreeNode.read('gg-tree/97_otus.tree')\n",
    "\n",
    "mf['days_since_epoch'] = pd.to_numeric(mf['days_since_epoch'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built a custom object that will handle alpha diversity, beta diversity and the creation of the microbial features. This object relies on the three objects described above and on two categories, one that identifies the subjects (``trajectories`` is set to ``host_subject_id``) and one that identifies the ordering of the samples per subject (``gradient`` is set to ``days_since_epoch``).\n",
    "\n",
    "This object will also take care of caching the distance matrices for the full dataset so that they are not computed at **every** iteration. Matrices will be saved under the `roc-curves/gg` directory, the name of the subfolder (that is `gg`), is determined by the `name` parameter in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "think = Sculptor(biom_table=bt, mapping_file=mf, tree=tree,\n",
    "                 gradient='days_since_epoch', trajectory='host_subject_id',\n",
    "                 name='gg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of including more samples per subject we use the performance of a classifier, and we randomly select $N$ samples from all the subjects over $M$ iterations. At each iteration we train a random forests model, and at the end we compare the performance at different values of $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a receiver operating characteristic curve with the data for all the 100 iterations. The source code to create the plot was taken from [scikit-learn's documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html). Note that we set up the classifier to use 4 cores, which might not be a good idea depending on where you run this source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lw = 2\n",
    "\n",
    "N = 100\n",
    "for N_samples in range(0, 12):\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.figure()\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        ## BEGIN feature creation\n",
    "        \n",
    "        # zero samples means \"traditional\" classifier\n",
    "        # with one sample per subject\n",
    "        think.randomly_select(1 if N_samples == 0 else N_samples)\n",
    "\n",
    "        # groups discovered by phylofactor\n",
    "        features_to_keep = []\n",
    "        for _, id_, md in think.biom_table.iter(axis='observation', dense=False):\n",
    "            t = md['taxonomy']\n",
    "            if (t[4].lower() == 'f__lachnospiraceae'\n",
    "                or t[2].lower() == 'c__gammaproteobacteria'\n",
    "                or t[2].lower() == 'c__betaproteobacteria'):\n",
    "                features_to_keep.append(id_)\n",
    "\n",
    "        # more than one sample\n",
    "        if N_samples > 1:\n",
    "            alpha = think.alpha_table(['faith_pd', 'chao1', 'brillouin_d'])\n",
    "            beta = think.beta_table()\n",
    "            features = think.microbes_over_time(ids=features_to_keep)\n",
    "            \n",
    "            # combine the data\n",
    "            combined_features = pd.concat([features, alpha, beta], axis=1)\n",
    "\n",
    "            # get a column with ibd status for all the subjects\n",
    "            combined_features.dropna(axis=1, how='any', inplace=True)\n",
    "            classes = think.mapping_file.groupby(['host_subject_id', 'ibd'],\n",
    "                                        as_index=False).aggregate(np.sum).set_index('host_subject_id',\n",
    "                                                                                    inplace=False)\n",
    "            combined_features['ibd'] = classes['ibd']\n",
    "        # one sample with our model\n",
    "        elif N_samples == 1:\n",
    "            alpha = think.alpha_table(['faith_pd', 'chao1', 'brillouin_d'], [abs_energy])\n",
    "            features = think.biom_table.filter(ids_to_keep=features_to_keep, axis='observation')\n",
    "            features = features.norm(inplace=False).to_dataframe().to_dense().T\n",
    "            features['host_subject_id'] = think.mapping_file['host_subject_id']\n",
    "            features['ibd'] = think.mapping_file['ibd']\n",
    "            features.set_index('host_subject_id', inplace=True)\n",
    "            combined_features = pd.concat([features, alpha], axis=1)\n",
    "        # one sample with only relative abundances\n",
    "        elif N_samples == 0:\n",
    "            combined_features = think.biom_table.norm(inplace=False).to_dataframe().to_dense().T\n",
    "            combined_features['ibd'] = think.mapping_file['ibd']\n",
    "\n",
    "        # get a list of the features without the labels\n",
    "        no_ibd = combined_features.columns.tolist()\n",
    "        no_ibd.remove('ibd')\n",
    "        ## END feature creation\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(combined_features[no_ibd],\n",
    "                                                            combined_features['ibd'],\n",
    "                                                            test_size=0.35)\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=500, n_jobs=4)\n",
    "        probas_ = clf.fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test, probas_[:, 1], pos_label='Crohns')\n",
    "        \n",
    "        # skip any results with np.nan values as it means\n",
    "        # the test/train split yieleded a bad selection\n",
    "        if np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "            continue \n",
    "        else:\n",
    "            mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "            mean_tpr[0] = 0.0\n",
    "            plt.plot(fpr, tpr, lw=0.1*lw, color='lightgray')\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',\n",
    "             label='Luck')\n",
    "\n",
    "    mean_tpr /= N\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',\n",
    "             label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc-curves/%s/%d.samples.per.subject-%d.iterations.pdf' % (think.name, N_samples, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
